from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

MODEL_NAME = "seara/rubert-tiny2-russian-sentiment"

print("üîÑ Loading RuBERT model...")

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)

LABELS = ["negative", "neutral", "positive"]

def analyze_sentiment(text: str):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
      label: str ‚Äî –º–µ—Ç–∫–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
      prob: float ‚Äî —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
    """
    encoded = tokenizer(text, return_tensors="pt", truncation=True)
    with torch.no_grad():
        output = model(**encoded)

    probs = torch.softmax(output.logits, dim=1)[0]
    label_id = torch.argmax(probs).item()
    return LABELS[label_id], float(probs[label_id])

from pydantic import BaseModel
from typing import List

class TextsRequest(BaseModel):
    texts: List[str]

class SentimentItem(BaseModel):
    text: str
    sentiment: str
    confidence: float

class SentimentResponse(BaseModel):
    results: List[SentimentItem]

from fastapi import FastAPI

app = FastAPI(
    title="Russian Sentiment API (RuBERT)",
    description="–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —á–µ—Ä–µ–∑ RuBERT",
    version="1.0.0"
)

@app.get("/")
def root():
    return {"status": "ok", "message": "RuBERT sentiment service is running"}

@app.post("/sentiment", response_model=SentimentResponse)
def sentiment_endpoint(req: TextsRequest):
    results = []
    for text in req.texts:
        label, conf = analyze_sentiment(text)
        results.append(SentimentItem(
            text=text,
            sentiment=label,
            confidence=conf
        ))
    return SentimentResponse(results=results)
